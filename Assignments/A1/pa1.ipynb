{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for the assignment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT: WHEN TRAINING A MODEL, RESTARTING THE KERNEL IS A MUST TO NOT OVERFIT. THIS ALSO AVOIDS DATA LEAKAGE BETWEEN THE TRAINING DATA AND THE TESTING DATA\n",
    "\n",
    "#Importing the facts.txt and the fakes.txt files to create our dataset \n",
    "\n",
    "# Turn fact.txt file into pandas DataFrame\n",
    "dfFacts = pd.read_table(\"facts.txt\", header=None)\n",
    "\n",
    "#Add last column and fill it with value of fact\n",
    "dfFacts.insert(0, \"Category\", \"fact\")\n",
    "\n",
    "#Add column names\n",
    "dfFacts.columns = ['Category', 'Text']\n",
    "#print(dfFacts)\n",
    "\n",
    "# Turn fact.txt file into pandas DataFrame\n",
    "dfFakes = pd.read_table(\"fakes.txt\", header=None)\n",
    "\n",
    "#Add last column and fill it with value of fact\n",
    "dfFakes.insert(0, \"Category\", \"fake\")\n",
    "\n",
    "#Add column names\n",
    "dfFakes.columns = ['Category', 'Text']\n",
    "#print(dfFakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>fact</td>\n",
       "      <td>Montreal's LGBTQ+ community is centered around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>fake</td>\n",
       "      <td>The city has a law that requires all citizens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>fake</td>\n",
       "      <td>The city’s wildlife is known for its karaoke n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>fake</td>\n",
       "      <td>The city has a law that allows residents to ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>fact</td>\n",
       "      <td>Formula 1’s Canadian Grand Prix is held annual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>fake</td>\n",
       "      <td>Every street corner in Montreal has a gnome gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>fact</td>\n",
       "      <td>The city hosts the annual Just for Laughs come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>fake</td>\n",
       "      <td>The city has a secret festival for the best pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>fact</td>\n",
       "      <td>Montreal hosted the World Expo in 1967, one of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>fake</td>\n",
       "      <td>The city has a hidden underwater city made ent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category                                               Text\n",
       "177     fact  Montreal's LGBTQ+ community is centered around...\n",
       "359     fake  The city has a law that requires all citizens ...\n",
       "325     fake  The city’s wildlife is known for its karaoke n...\n",
       "258     fake  The city has a law that allows residents to ke...\n",
       "71      fact  Formula 1’s Canadian Grand Prix is held annual...\n",
       "..       ...                                                ...\n",
       "238     fake  Every street corner in Montreal has a gnome gu...\n",
       "41      fact  The city hosts the annual Just for Laughs come...\n",
       "378     fake  The city has a secret festival for the best pa...\n",
       "194     fact  Montreal hosted the World Expo in 1967, one of...\n",
       "267     fake  The city has a hidden underwater city made ent...\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Making one global dataframe with both facts and fakes together (this will make the data manipulation easier)\n",
    "dataframes = [dfFacts, dfFakes]\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "#The following code is used to randomize are dataset now.\n",
    "df = df.sample(n=len(df))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before doing any testing on hyperparameters and any preprocessing, we will train our models and then test on a basic 80%/20% data split to compare \n",
    "#the models when no preprocessing is done.\n",
    "\n",
    "#Input Values for the model\n",
    "X = df['Text']\n",
    "\n",
    "#Expected output\n",
    "y = df['Category']\n",
    "\n",
    "#Create the 80/20 split for training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BNB model: 0.9625\n",
      "Accuracy of SVM model: 0.9125\n",
      "Accuracy of LR model: 0.95\n"
     ]
    }
   ],
   "source": [
    "#Create a pipeline for each model (we will first use Count Vectorizer, and thenTfidVectorizer)\n",
    "pipelineBNB = Pipeline([(\"vectorize\", CountVectorizer()), (\"classifier\", BernoulliNB())])\n",
    "pipelineSVM = Pipeline([(\"vectorize\", CountVectorizer()), (\"classifier\", LinearSVC())])\n",
    "pipelineLR = Pipeline([(\"vectorize\", CountVectorizer()), (\"classifier\", LogisticRegression())])\n",
    "\n",
    "#Train the models\n",
    "pipelineBNB.fit(X_train, y_train)\n",
    "pipelineSVM.fit(X_train, y_train)\n",
    "pipelineLR.fit(X_train, y_train)\n",
    "\n",
    "#Test the models\n",
    "predictionBNB = pipelineBNB.predict(X_test)\n",
    "predictionSVM = pipelineSVM.predict(X_test)\n",
    "predictionLR = pipelineLR.predict(X_test)\n",
    "\n",
    "#Accuracy of models\n",
    "print(f\"Accuracy of BNB model: {accuracy_score(y_test, predictionBNB)}\")\n",
    "print(f\"Accuracy of SVM model: {accuracy_score(y_test, predictionSVM)}\")\n",
    "print(f\"Accuracy of LR model: {accuracy_score(y_test, predictionLR)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BNB model: 0.9625\n",
      "Accuracy of SVM model: 0.975\n",
      "Accuracy of LR model: 0.9625\n"
     ]
    }
   ],
   "source": [
    "#We will now to the same process for the TfidVectorizer\n",
    "\n",
    "pipelineBNB = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", BernoulliNB())])\n",
    "pipelineSVM = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", LinearSVC())])\n",
    "pipelineLR = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", LogisticRegression())])\n",
    "\n",
    "#Train the models\n",
    "pipelineBNB.fit(X_train, y_train)\n",
    "pipelineSVM.fit(X_train, y_train)\n",
    "pipelineLR.fit(X_train, y_train)\n",
    "\n",
    "#Test the models\n",
    "predictionBNB = pipelineBNB.predict(X_test)\n",
    "predictionSVM = pipelineSVM.predict(X_test)\n",
    "predictionLR = pipelineLR.predict(X_test)\n",
    "\n",
    "#Accuracy of models\n",
    "print(f\"Accuracy of BNB model: {accuracy_score(y_test, predictionBNB)}\")\n",
    "print(f\"Accuracy of SVM model: {accuracy_score(y_test, predictionSVM)}\")\n",
    "print(f\"Accuracy of LR model: {accuracy_score(y_test, predictionLR)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>fact</td>\n",
       "      <td>Montreal's LGBTQ+ community be center around T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>fake</td>\n",
       "      <td>The city have a law that require all citizens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>fake</td>\n",
       "      <td>The city’s wildlife be know for its karaoke ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>fake</td>\n",
       "      <td>The city have a law that allow residents to ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>fact</td>\n",
       "      <td>Formula 1’s Canadian Grand Prix be hold annual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>fake</td>\n",
       "      <td>Every street corner in Montreal have a gnome g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>fact</td>\n",
       "      <td>The city host the annual Just for Laughs comed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>fake</td>\n",
       "      <td>The city have a secret festival for the best p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>fact</td>\n",
       "      <td>Montreal host the World Expo in 1967, one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>fake</td>\n",
       "      <td>The city have a hide underwater city make enti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category                                               Text\n",
       "177     fact  Montreal's LGBTQ+ community be center around T...\n",
       "359     fake  The city have a law that require all citizens ...\n",
       "325     fake  The city’s wildlife be know for its karaoke ni...\n",
       "258     fake  The city have a law that allow residents to ke...\n",
       "71      fact  Formula 1’s Canadian Grand Prix be hold annual...\n",
       "..       ...                                                ...\n",
       "238     fake  Every street corner in Montreal have a gnome g...\n",
       "41      fact  The city host the annual Just for Laughs comed...\n",
       "378     fake  The city have a secret festival for the best p...\n",
       "194     fact  Montreal host the World Expo in 1967, one of t...\n",
       "267     fake  The city have a hide underwater city make enti...\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>fact</td>\n",
       "      <td>montreal lgbtq+ communiti be center around the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>fake</td>\n",
       "      <td>the citi have a law that requir all citizen to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>fake</td>\n",
       "      <td>the citi wildlif be know for it karaok nights.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>fake</td>\n",
       "      <td>the citi have a law that allow resid to keep p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>fact</td>\n",
       "      <td>formula 1 canadian grand prix be hold annual a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>fake</td>\n",
       "      <td>everi street corner in montreal have a gnome g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>fact</td>\n",
       "      <td>the citi host the annual just for laugh comedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>fake</td>\n",
       "      <td>the citi have a secret festiv for the best pan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>fact</td>\n",
       "      <td>montreal host the world expo in 1967, one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>fake</td>\n",
       "      <td>the citi have a hide underwat citi make entir ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category                                               Text\n",
       "177     fact  montreal lgbtq+ communiti be center around the...\n",
       "359     fake  the citi have a law that requir all citizen to...\n",
       "325     fake     the citi wildlif be know for it karaok nights.\n",
       "258     fake  the citi have a law that allow resid to keep p...\n",
       "71      fact  formula 1 canadian grand prix be hold annual a...\n",
       "..       ...                                                ...\n",
       "238     fake  everi street corner in montreal have a gnome g...\n",
       "41      fact  the citi host the annual just for laugh comedi...\n",
       "378     fake  the citi have a secret festiv for the best pan...\n",
       "194     fact  montreal host the world expo in 1967, one of t...\n",
       "267     fake  the citi have a hide underwat citi make entir ...\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The accuracy results have increased significant amounts except for the BNB model simply by switching the vectorizing process after the first attempt\n",
    "#(LR by 5% and SVM by 10%)\n",
    "#We will continue to use TfidVectorizer for the rest of the tests given it's more accurate results.\n",
    "\n",
    "#We will now compare both Lemmatization and Stemming.\n",
    "dfLemma = df\n",
    "dfStem = df\n",
    "\n",
    "#We now Lemmatize the dataset\n",
    "#THIS HELPER FUNCTION IS NOT MINE, I USED THE FOLLOWING CODE SNIPPET TO HELP WITH LEMMETIZATION: https://www.datasnips.com/90/lemmatise-dataframe-text-using-nltk/\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word, pos=\"v\") for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "dfLemma['Text'] = dfLemma['Text'].apply(lemmatize_words)\n",
    "display(dfLemma)\n",
    "\n",
    "\n",
    "#Stemming the words in the dataset (inspired by the lemmatization function above)\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "def stem_words(text):\n",
    "    words = text.split()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "dfStem['Text'] = dfStem['Text'].apply(stem_words)\n",
    "display(dfStem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BNB model with Lemmatization: 0.95\n",
      "Accuracy of SVM model with Lemmatization: 0.9625\n",
      "Accuracy of LR model with Lemmatization: 0.975\n"
     ]
    }
   ],
   "source": [
    "#We recreate the pipleine the same as before but with the lemmatized data\n",
    "#Input Values for the Lemmatized data\n",
    "X = dfLemma['Text']\n",
    "\n",
    "#display(dfLemma)\n",
    "\n",
    "#Expected output\n",
    "y = dfLemma['Category']\n",
    "\n",
    "#Create the 80/20 split for training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "\n",
    "pipelineBNB = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", BernoulliNB())])\n",
    "pipelineSVM = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", LinearSVC())])\n",
    "pipelineLR = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", LogisticRegression())])\n",
    "\n",
    "#Train the models\n",
    "pipelineBNB.fit(X_train, y_train)\n",
    "pipelineSVM.fit(X_train, y_train)\n",
    "pipelineLR.fit(X_train, y_train)\n",
    "\n",
    "#Test the models\n",
    "predictionBNB = pipelineBNB.predict(X_test)\n",
    "predictionSVM = pipelineSVM.predict(X_test)\n",
    "predictionLR = pipelineLR.predict(X_test)\n",
    "\n",
    "#Accuracy of models\n",
    "print(f\"Accuracy of BNB model with Lemmatization: {accuracy_score(y_test, predictionBNB)}\")\n",
    "print(f\"Accuracy of SVM model with Lemmatization: {accuracy_score(y_test, predictionSVM)}\")\n",
    "print(f\"Accuracy of LR model with Lemmatization: {accuracy_score(y_test, predictionLR)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BNB model with Lemmatization: 0.95\n",
      "Accuracy of SVM model with Lemmatization: 0.9625\n",
      "Accuracy of LR model with Lemmatization: 0.975\n"
     ]
    }
   ],
   "source": [
    "#We recreate the pipleine the same as before but with the stemmed data\n",
    "#Input Values for the stemmed data\n",
    "X = dfStem['Text']\n",
    "\n",
    "#print(X)\n",
    "\n",
    "#Expected output\n",
    "y = dfStem['Category']\n",
    "\n",
    "#Create the 80/20 split for training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "\n",
    "pipelineBNB = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", BernoulliNB())])\n",
    "pipelineSVM = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", LinearSVC())])\n",
    "pipelineLR = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", LogisticRegression())])\n",
    "\n",
    "#Train the models\n",
    "pipelineBNB.fit(X_train, y_train)\n",
    "pipelineSVM.fit(X_train, y_train)\n",
    "pipelineLR.fit(X_train, y_train)\n",
    "\n",
    "#Test the models\n",
    "predictionBNB = pipelineBNB.predict(X_test)\n",
    "predictionSVM = pipelineSVM.predict(X_test)\n",
    "predictionLR = pipelineLR.predict(X_test)\n",
    "\n",
    "#Accuracy of models\n",
    "print(f\"Accuracy of BNB model with Lemmatization: {accuracy_score(y_test, predictionBNB)}\")\n",
    "print(f\"Accuracy of SVM model with Lemmatization: {accuracy_score(y_test, predictionSVM)}\")\n",
    "print(f\"Accuracy of LR model with Lemmatization: {accuracy_score(y_test, predictionLR)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BNB model with stop-words removed: 0.9\n",
      "Accuracy of SVM model stop-words removed: 0.975\n",
      "Accuracy of LR model stop-words removed: 0.975\n"
     ]
    }
   ],
   "source": [
    "#Stemming and Lemmatization did not do much in terms of accuracy and in some cases it even diminished by a little bit.\n",
    "#We will now test two other pre-processing techniques without using stemming or lemmatization since they do not add a clear benefit to our accuracy.\n",
    "\n",
    "#We will test stop_words usage through the TfidfVectorizer directly\n",
    "\n",
    "pipelineBNB = Pipeline([(\"vectorize\", TfidfVectorizer(stop_words=\"english\")), (\"classifier\", BernoulliNB())])\n",
    "pipelineSVM = Pipeline([(\"vectorize\", TfidfVectorizer(stop_words=\"english\")), (\"classifier\", LinearSVC())])\n",
    "pipelineLR = Pipeline([(\"vectorize\", TfidfVectorizer(stop_words=\"english\")), (\"classifier\", LogisticRegression())])\n",
    "\n",
    "#Train the models\n",
    "pipelineBNB.fit(X_train, y_train)\n",
    "pipelineSVM.fit(X_train, y_train)\n",
    "pipelineLR.fit(X_train, y_train)\n",
    "\n",
    "#Test the models\n",
    "predictionBNB = pipelineBNB.predict(X_test)\n",
    "predictionSVM = pipelineSVM.predict(X_test)\n",
    "predictionLR = pipelineLR.predict(X_test)\n",
    "\n",
    "#Accuracy of models\n",
    "print(f\"Accuracy of BNB model with stop-words removed: {accuracy_score(y_test, predictionBNB)}\")\n",
    "print(f\"Accuracy of SVM model stop-words removed: {accuracy_score(y_test, predictionSVM)}\")\n",
    "print(f\"Accuracy of LR model stop-words removed: {accuracy_score(y_test, predictionLR)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BNB model with 2-gram: 0.8875\n",
      "Accuracy of SVM model 2-gram: 0.975\n",
      "Accuracy of LR model 2-gram: 0.975\n"
     ]
    }
   ],
   "source": [
    "#Removing the Stop-Words produced worse results than without removing the stop-words. Giving that we do not have an extansive dataset, this makes sense as \n",
    "#we should not be removing words when our quantity of them is already quite limited.\n",
    "\n",
    "#We will now test n-grams with n=1 to n= (unigrams to bigrams) and then we will do form n=1 to n=3 (unigrams, bigrams and trigrams)\n",
    "\n",
    "#n=1 to n=2\n",
    "\n",
    "pipelineBNB = Pipeline([(\"vectorize\", TfidfVectorizer(ngram_range=(1, 2))), (\"classifier\", BernoulliNB())])\n",
    "pipelineSVM = Pipeline([(\"vectorize\", TfidfVectorizer(ngram_range=(1, 2))), (\"classifier\", LinearSVC())])\n",
    "pipelineLR = Pipeline([(\"vectorize\", TfidfVectorizer(ngram_range=(1, 2))), (\"classifier\", LogisticRegression())])\n",
    "\n",
    "#Train the models\n",
    "pipelineBNB.fit(X_train, y_train)\n",
    "pipelineSVM.fit(X_train, y_train)\n",
    "pipelineLR.fit(X_train, y_train)\n",
    "\n",
    "#Test the models\n",
    "predictionBNB = pipelineBNB.predict(X_test)\n",
    "predictionSVM = pipelineSVM.predict(X_test)\n",
    "predictionLR = pipelineLR.predict(X_test)\n",
    "\n",
    "#Accuracy of models\n",
    "print(f\"Accuracy of BNB model with 2-gram: {accuracy_score(y_test, predictionBNB)}\")\n",
    "print(f\"Accuracy of SVM model 2-gram: {accuracy_score(y_test, predictionSVM)}\")\n",
    "print(f\"Accuracy of LR model 2-gram: {accuracy_score(y_test, predictionLR)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BNB model with 3-gram: 0.7125\n",
      "Accuracy of SVM model 3-gram: 0.975\n",
      "Accuracy of LR model 3-gram: 0.9625\n"
     ]
    }
   ],
   "source": [
    "#Using n-grams from n=1 to n=2 seemed to have increased the accuracy for the models.\n",
    "\n",
    "#n=1 to n=3\n",
    "\n",
    "pipelineBNB = Pipeline([(\"vectorize\", TfidfVectorizer(ngram_range=(1, 3))), (\"classifier\", BernoulliNB())])\n",
    "pipelineSVM = Pipeline([(\"vectorize\", TfidfVectorizer(ngram_range=(1, 3))), (\"classifier\", LinearSVC())])\n",
    "pipelineLR = Pipeline([(\"vectorize\", TfidfVectorizer(ngram_range=(1, 3))), (\"classifier\", LogisticRegression())])\n",
    "\n",
    "#Train the models\n",
    "pipelineBNB.fit(X_train, y_train)\n",
    "pipelineSVM.fit(X_train, y_train)\n",
    "pipelineLR.fit(X_train, y_train)\n",
    "\n",
    "#Test the models\n",
    "predictionBNB = pipelineBNB.predict(X_test)\n",
    "predictionSVM = pipelineSVM.predict(X_test)\n",
    "predictionLR = pipelineLR.predict(X_test)\n",
    "\n",
    "#Accuracy of models\n",
    "print(f\"Accuracy of BNB model with 3-gram: {accuracy_score(y_test, predictionBNB)}\")\n",
    "print(f\"Accuracy of SVM model 3-gram: {accuracy_score(y_test, predictionSVM)}\")\n",
    "print(f\"Accuracy of LR model 3-gram: {accuracy_score(y_test, predictionLR)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with n=1 to n=3 drastically reduced the accuracy of the BNB model, without increasing the accuracy of the other models.\n",
    "#We will therefore reamin with n=1 to n=2 for the n-grams preprocessing parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "{'classifier__C': 1, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Accuracy Score: \n",
      "0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "20 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_classes.py\", line 317, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1214, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py\", line 1046, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [     nan 0.78125  0.646875 0.9125        nan 0.925    0.85625  0.928125\n",
      "      nan 0.90625  0.86875  0.90625       nan 0.90625  0.875    0.90625 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#We will now train the hyperparameters of each model while doing 5-Fold Cross Validation which means each fold will constitue 20% of our data. \n",
    "# The reason for using cross-validation is simply because our corpus of information is quite small (400 entries)\n",
    "# We will use GridSearchCV to accomplish our hyperparameter tuning for all models.\n",
    "\n",
    "#We start with the tuning of the SVM\n",
    "pipelineSVM = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", LinearSVC())])\n",
    "\n",
    "#Defining parameters \n",
    "parametersLSVC = [{'classifier__C': [0.1, 1, 10, 100],  \n",
    "              'classifier__loss': ['hinge', 'squared_hinge'], \n",
    "              'classifier__penalty':['l1', 'l2']}]\n",
    "\n",
    "LSVC_CV = GridSearchCV(pipelineSVM, param_grid=parametersLSVC, scoring='accuracy', cv=5)\n",
    "\n",
    "#This will give us the best training parameters\n",
    "LSVC_CV.fit(X_train, y_train)\n",
    "print(\"Best Parameters: \")\n",
    "print(LSVC_CV.best_params_)\n",
    "\n",
    "#Test on Test Set\n",
    "predictions = LSVC_CV.predict(X_test) \n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "{'classifier__alpha': 0.1, 'classifier__fit_prior': True}\n",
      "Accuracy Score: \n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "#We now do the tuning of the Naive Bayes model (Bernouilli)\n",
    "pipelineBNB = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", BernoulliNB())])\n",
    "\n",
    "#Defining Parameters\n",
    "parametersBNB = [{'classifier__alpha': [0.1, 1, 10, 100],  \n",
    "              'classifier__fit_prior': [True, False]}]\n",
    "\n",
    "BNB_CV = GridSearchCV(pipelineBNB, param_grid=parametersBNB, scoring='accuracy', cv=5)\n",
    "\n",
    "#This will give us the best training parameters\n",
    "BNB_CV.fit(X_train, y_train)\n",
    "print(\"Best Parameters: \")\n",
    "print(BNB_CV.best_params_)\n",
    "\n",
    "#Test on Test Set\n",
    "predictions = BNB_CV.predict(X_test) \n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "{'classifier__C': 10, 'classifier__penalty': 'l2'}\n",
      "Accuracy Score: \n",
      "0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [     nan 0.890625      nan      nan 0.909375      nan      nan 0.925\n",
      "      nan      nan 0.915625      nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#We start with the tuning of the SVM\n",
    "pipelineLR = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"classifier\", LogisticRegression())])\n",
    "\n",
    "#Defining Parameters\n",
    "parametersLR = [{'classifier__C': [0.1, 1, 10, 100],  \n",
    "              'classifier__penalty':['l1', 'l2', 'elasticnet']}]\n",
    "\n",
    "LR_CV = GridSearchCV(pipelineLR, param_grid=parametersLR, scoring='accuracy', cv=5)\n",
    "\n",
    "#This will give us the best training parameters\n",
    "LR_CV.fit(X_train, y_train)\n",
    "print(\"Best Parameters: \")\n",
    "print(LR_CV.best_params_)\n",
    "\n",
    "#Test on Test Set\n",
    "predictions = LR_CV.predict(X_test) \n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the final BNB model: 0.9625\n"
     ]
    }
   ],
   "source": [
    "#After fien tuning, each model had an increase in accuracy besides linear SVM. This could be because the default parameters of the linear SVM might be similar to the best \n",
    "#parameters after fine-tuning.\n",
    "\n",
    "#Now, we will do one final experiement where we will take the best performing model, and combine it with the best pre-processing techniques.\n",
    "\n",
    "#The best model after fine-tuning was the Bernouilli Naive Bayes with parameters {'classifier__alpha': 0.1, 'classifier__fit_prior': True}. \n",
    "#We will ignore stemming, lemmatizing, and removing stop-words giving that they did not influence the accuracy.\n",
    "#We will include bingrams from n=1 to n=2 since it did influence postively our accuracy.\n",
    "\n",
    "#Create a pipeline for each model thenTfidVectorizer\n",
    "pipelineBNBFinal = Pipeline([(\"vectorize\", TfidfVectorizer(ngram_range=(1, 2))), (\"classifier\", BernoulliNB(alpha=0.1, fit_prior=True))])\n",
    "\n",
    "\n",
    "#Train the model\n",
    "pipelineBNBFinal.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Test the models\n",
    "predictionBNBFinal = pipelineBNBFinal.predict(X_test)\n",
    "\n",
    "#Accuracy of models\n",
    "print(f\"Accuracy of the final BNB model: {accuracy_score(y_test, predictionBNBFinal)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The accuracy actually increased minimally.\n",
    "\n",
    "#Limitations of the study: The biggest limit of this study is the fact that our dataset is too small. To be able to detect whether something is a fact or not in a more\n",
    "#accurate fashion, we would need to have tons more data. Furthermore, fine-tuning the hypeparameters would need to go hand in hand with preprocessing techinques,\n",
    "# #to be able to get, not only the best possible parameters for a given model, but to also get the best combination of hyperparameters and preprocessing techniques\n",
    "# #used together.\n",
    "# \n",
    "# Speculates on the generalizability of the results of this study: I do not believe it to be very generalizable given that our dataset is extremely small \n",
    "# and facts about Montréal were the only facts used. Indeed, to create something that would be able to be generalized, we would need tons more data on many more cities. \n",
    "# Additionally, our data comes from a generative AI model, and we’ve assumed that everything is has generated for us is correct, when in reality, \n",
    "# the model may have supplied inaccurate facts, which can lead to training a model with bad data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
